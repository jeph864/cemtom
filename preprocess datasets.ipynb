{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cf072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import cemtom\n",
    "from cemtom.dataset._20newgroup import fetch_dataset\n",
    "from cemtom.preprocessing import Preprocessor\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import importlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e63f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "#importlib.reload(cemtom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6d5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = spacy.load('en_core_web_sm')\n",
    "tokenizer = spacy_model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c42c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%reload_ext autoreload\n",
    "token_dict={\n",
    "    \"doc_start_token\": '<s>',\n",
    "    \"doc_end_token\":'</s>',\n",
    "    \"unk_token\":'<unk>',\n",
    "    \"email_token\":'<email>',\n",
    "    \"url_token\":'<url>',\n",
    "    \"number_token\":'<number>',\n",
    "    \"alpha_num_token\":'<alpha_num>'\n",
    "}\n",
    "preprocessor = Preprocessor(stopwords_list=\"english\", remove_spacy_stopwords = False,\n",
    "                            token_dict=token_dict, use_spacy_tokenizer=True, min_df\n",
    "                           max_df = 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49441974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.8, min_df=0.0,\n",
       "                stop_words=[&#x27;a&#x27;, &#x27;able&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;according&#x27;,\n",
       "                            &#x27;accordingly&#x27;, &#x27;across&#x27;, &#x27;actually&#x27;, &#x27;after&#x27;,\n",
       "                            &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;, &#x27;allow&#x27;,\n",
       "                            &#x27;allows&#x27;, &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                            &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                            &#x27;amongst&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anybody&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.8, min_df=0.0,\n",
       "                stop_words=[&#x27;a&#x27;, &#x27;able&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;according&#x27;,\n",
       "                            &#x27;accordingly&#x27;, &#x27;across&#x27;, &#x27;actually&#x27;, &#x27;after&#x27;,\n",
       "                            &#x27;afterwards&#x27;, &#x27;again&#x27;, &#x27;against&#x27;, &#x27;all&#x27;, &#x27;allow&#x27;,\n",
       "                            &#x27;allows&#x27;, &#x27;almost&#x27;, &#x27;alone&#x27;, &#x27;along&#x27;, &#x27;already&#x27;,\n",
       "                            &#x27;also&#x27;, &#x27;although&#x27;, &#x27;always&#x27;, &#x27;am&#x27;, &#x27;among&#x27;,\n",
       "                            &#x27;amongst&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;another&#x27;, &#x27;any&#x27;, &#x27;anybody&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_df=0.8, min_df=0.0,\n",
       "                stop_words=['a', 'able', 'about', 'above', 'according',\n",
       "                            'accordingly', 'across', 'actually', 'after',\n",
       "                            'afterwards', 'again', 'against', 'all', 'allow',\n",
       "                            'allows', 'almost', 'alone', 'along', 'already',\n",
       "                            'also', 'although', 'always', 'am', 'among',\n",
       "                            'amongst', 'an', 'and', 'another', 'any', 'anybody', ...])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463b3a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to extract the dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataset_raw = fetch_dataset(remove=[\"headers\", \"footers\", \"quotes\"])\n",
    "dataset = fetch_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc958dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cemtom.dataset.dataset.Dataset at 0x14cb140c23d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e7f99",
   "metadata": {},
   "source": [
    "Try out the spacy tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56132d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a798bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_doc = []\n",
    "for doc in tokenizer.pipe([dataset[1][0]]):\n",
    "    for token in doc:\n",
    "        if token.is_alpha:\n",
    "            new_doc.append(token.text)\n",
    "        elif 'number_token' in preprocessor.token_dict and token.is_digit:\n",
    "            new_doc.append(preprocessor.token_dict['number_token'])\n",
    "        elif 'email_token' in preprocessor.token_dict and token.like_email:\n",
    "            new_doc.append(preprocessor.token_dict['email_token'])\n",
    "        elif 'url_token' in preprocessor.token_dict and token.like_url:\n",
    "            new_doc.append(preprocessor.token_dict['url_token'])\n",
    "        elif 'alpha_num_token' in preprocessor.token_dict and token.text.isalnum():\n",
    "            new_doc.append(preprocessor.token_dict['alpha_num_token'])\n",
    "        elif 'unk_token' in preprocessor.token_dict and token.is_oov:\n",
    "            new_doc.append(preprocessor.token_dict['unk_token'])\n",
    "        else:\n",
    "            new_doc.append(token.text)\n",
    "        \n",
    "        \n",
    "\" \".join(new_doc)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cbc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(tokenizer.pipe([dataset_raw[1][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"idx\": dataset.get_indices(),\n",
    "    \"labels\": dataset.get_labels(),\n",
    "    \"documents\": dataset.get_corpus()\n",
    "}\n",
    "d = pd.DataFrame(data)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca22493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18846/18846 [00:00<00:00, 110129.76it/s]\n",
      "100%|██████████| 18846/18846 [00:07<00:00, 2462.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering 18846\n",
      "vocab created 83526\n"
     ]
    }
   ],
   "source": [
    "#%reload_ext autoreload\n",
    "#preprocessor = Preprocessor(stopwords_list=\"english\", remove_spacy_stopwords = False)\n",
    "ds = preprocessor.preprocess(None,dataset=dataset, num_processes = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b668fd70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['university washington seattle nntp posting host danny phornprapha writes car future narrow choice opnion danny question past year find share magistic answer work hard cheers issa suggestion work hard issa suggested acura nsx enjoy',\n",
       "  'monitor xga news software ibm pm rn vishnepolsky rogers reply ibm watson research hosek writes recommended monitor xga svga monitor needed curious blowing monster wad cash system xga original xga interlaced compatible idea prefer syncs ibm necs fixed frequency monitor home viewsonic multisyncs easy run modes colors noninterlaced higher modes dick kaul opinions official ibm positions ibm xga development make wear suit speak ibm boca raton fl shhhh maestro decomposing',\n",
       "  'russ sharp true type font problem repost deakin university victoria australia distribution world nntp posting host word show period centred character spaces ttfonts coreldraw editors spaces text character displayed large hollow box overlap characters side useless character period centred character shows windows charmap display hollow box confirm edited corel font fontmonger changing font graphics character makes difference font output charmap altering paragraph cedilla alter font graphics displayed character spaces period centred character character displayed coreldraw ttf russ sharp ph fax deakin university school engineering technology geelong australia',\n",
       "  'brad hernlem hezbollah reply brad hernlem ncsu chem eng article sessions writes clarify standards rules engagement understand israelis times circumstances fair targets opponents legitimate targets mirandized makes perfect sense grant israelis black hats killing automatically good thing hezbollah corollary hezbollah white hats good thing israelis prove bad guys attacking sounds suspiciously hockey fan cheers players team stick permanently rearrange opponent face curses ref penalizing side roles reversed sessions noted cheering attack israeli patrol inside lebanese territory condemning retaliatory shelling lebanese villages israeli israeli backed forces team playing fair opposing team rearranging faces spectators team viewing stands speak find sources news lebanon propaganda priori black white hats wonders idf bombard villages retaliation pin point attacks soldiers lebanon call lebanese terrorists brad hernlem',\n",
       "  'oliver muoto sale simms macintosh university southern california los angeles ca nntp posting host sale meg simms macintosh aka fastones interested email offer',\n",
       "  'charles brasted thoughts university adelaide distribution world nntp posting host keywords dan bissell dan lawrence bissell writes start christian makes sense read tony campollo liar lunatic real thing title writes book part effort destroy christianity process christian assume posting encourage comments history tony campello read arguements summing book jesus god listen perspective gain listening good hear reasonable christians christian scientists note australia strong movement bunch christian scientists single event bible true rational explanation justified laws physics chaps prove age universe years error conventional calculations result fact speed light rapidly decaying years accounted book jesus liar crazy modern day koresh existed bible story intended manifesto billion people tony follow reasons liar die lie people liar people gathered gathered hearing healed millions people died lie point difficult substantiate defined great religious arguments work aztec warriors sacrificed gods belief act bring victory spanish invaders list endless aztecs lost btw call fool heal people perfectly reasonable grounds christian point add weight claim jesus real thing niether lunatic entire nation drawn crazy doubtful fact rediculous drawn david koresh fool logical people documentary rise nazi germany point tony mention call werner heisenberg colleagues fools illogical men support hitler based presume emotional issue rational agreement principles argument invalid tony thought hitler sane liar lunatic real thing hmmm arguments warrant things note fulfilled loads prophecies psalms isaiah hrs betrayal crucifixion bible moment time write alot religious discussions people result quoting bible reasonable people bible treat stories sort metaphorical representation messages authors present interpret parts bible literally end sorts shit tony argument perfectly reasonable people events bible place convince thinks bible total fiction jesus real quoting book totally pointless mathematics equal equal people understand christian possibly explain people killed religious wars hundreds versions claiming correct lot churches life total sacrafice god sake loved die save hey ca god inspires turn lives tuff people real christian strong persevere weight lifting guitar playing drums takes time rush day christianity life church week helping poor people box time units work time sports tv social life god boxes carried boxes created posted part flames understood emotional sentiments stranger interest people famous evils life polititians churchs rules fear living fear dead pressed find exact quotation cheers charles',\n",
       "  'derek atkins screw people crypto hard core hackers spooks massachusetts institute technology nntp posting host reply message apr gmt article david sternlight writes countries laws importing crypto gear license scheme wo work legally countries including france david bzzt wrong crypto import laws derek atkins mit electrical engineering computer science secretary mit student information processing board sipb mit media laboratory speech research group pp asel',\n",
       "  'vance gloster compositing pictures pc inference corporation nntp posting host reply message sat gmt article patrick chu writes wondering graphics package pc compositing series pictures compositing live video clip digitized panning living room computer generated bird flying screen combine series pictures bird frames black living room picture show realize genlock genlock manual compositing composite frame time assumed composite series frames looked found pc package perform live animation computer generated animation autodesk animator format autodesk animator animation make color clear overlay animation convert files animator files animator import series files create animation video capture stuff create work gloster',\n",
       "  'dave bernard impeach clinton reno reply sun microsystems nntp posting host heartily agree batf warrant unsealed clear clinton reno supported illegal raid authority knock raid authority helicopters authority search drug lab apparently authority search automatic weapons days government lies missed give update warrant heard unsealed authority knock news wiretap summarize',\n",
       "  'thomas stevenson xcomm imakefile files keywords xcomm imakefile distribution world wayne state university nntp posting host installed apps imakefiles startingwith xcomm xmkmf create makefile makefile xcomm comment edit make command barfs wondering wrong make command dislike'],\n",
       " ['rec.autos',\n",
       "  'comp.sys.ibm.pc.hardware',\n",
       "  'comp.os.ms-windows.misc',\n",
       "  'talk.politics.mideast',\n",
       "  'misc.forsale',\n",
       "  'alt.atheism',\n",
       "  'sci.crypt',\n",
       "  'comp.graphics',\n",
       "  'talk.politics.guns',\n",
       "  'comp.windows.x'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4edd01cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3507"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds._Dataset__indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33df5358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"From: nsx@carson.u.washington.edu (|ns-x|)\\nSubject: Re: 300ZX or SC300???\\nOrganization: University of Washington, Seattle\\nLines: 18\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\n>ip02@ns1.cc.lehigh.edu (Danny Phornprapha) writes:\\n>>I'm getting a car in the near future.  I've narrow it down to 300ZX and SC300.\\n>>Which might be a better choice?\\n>>Thanks for your opnion,\\n>>Danny\\n\\n\\n>I've been asking myself this same question for the past year, so, if/when\\n>you find out, would you please share the magistic answer with me.. \\n>The way I see it right now, work twice as hard so you can have both.\\n>cheers :)\\n>Issa\\n\\n\\t\\n\\tmy suggestion is: why not work twice as hard (like issa \\n\\tsuggested above) then get acura nsx?! :) enjoy. /seb\\n\\n\\n\",\n",
       " 'rec.autos')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3507]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d73787f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.vectorizer = CountVectorizer(max_df=preprocessor.max_df, min_df=preprocessor.min_df, lowercase=preprocessor.lowercase,\n",
    "                                              #token_pattern=r\"(?u)\\b[\\w|\\-]{\" + str(preprocessor.min_chars) + r\",}\\b\",\n",
    "                                              stop_words=preprocessor.stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef0296f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaa', 'aaaa', 'aaaaa', 'aaaaaaaaaaaa', 'aaaaagggghhhh',\n",
       "       'aaaaarrrrgh', 'aaaah', 'aaaahhh', 'aaaall', 'aaaarrgghhhh',\n",
       "       'aaack', 'aaaggghhh', 'aaah', 'aaahh', 'aaahhhh', 'aaai',\n",
       "       'aaauuugggghhhhh', 'aab', 'aacc', 'aachen', 'aacs', 'aagain',\n",
       "       'aah', 'aaj', 'aalborg', 'aalternate', 'aaltonen', 'aam',\n",
       "       'aamazing', 'aamir', 'aams', 'aan', 'aanbieden', 'aand', 'aanerud',\n",
       "       'aangeboden', 'aangegeven', 'aangezien', 'aantal', 'aao', 'aap',\n",
       "       'aaplay', 'aardvark', 'aargh', 'aarghhhh', 'aarhus', 'aario',\n",
       "       'aarnet', 'aaron', 'aaronaw', 'aaronson', 'aaroundpluto', 'aarp',\n",
       "       'aarseth', 'aarskog', 'aas', 'aasked', 'aat', 'aatchoo', 'aatdb',\n",
       "       'aavso', 'aawin', 'aazaadee', 'ab', 'ababa', 'ababs', 'abacus',\n",
       "       'abad', 'abandon', 'abandond', 'abandondoning', 'abandoned',\n",
       "       'abandoning', 'abandonment', 'abandons', 'abate', 'abatement',\n",
       "       'abates', 'abba', 'abbas', 'abbasids', 'abbasov', 'abberant',\n",
       "       'abberation', 'abberley', 'abbey', 'abbie', 'abbot', 'abbott',\n",
       "       'abbotts', 'abboud', 'abbrev', 'abbreviated', 'abbreviation',\n",
       "       'abbreviations', 'abc', 'abcdef', 'abd', 'abdallah', 'abdeen',\n",
       "       'abdel', 'abdelhamoud', 'abdelmalek', 'abdi', 'abdicate',\n",
       "       'abdication', 'abdo', 'abdomen', 'abdomens', 'abdominal', 'abduct',\n",
       "       'abducted', 'abduction', 'abdul', 'abdulcebbar', 'abdulhamid',\n",
       "       'abdulla', 'abdullah', 'abdullahad', 'abe', 'abed', 'abeit',\n",
       "       'abekas', 'abel', 'aben', 'abensberg', 'aber', 'aberdeen',\n",
       "       'abernathy', 'aberrant', 'aberration', 'aberrations',\n",
       "       'aberystwyth', 'abetted', 'abetter', 'abetting', 'abfp', 'abg',\n",
       "       'abgarovich', 'abhijit', 'abhin', 'abhor', 'abhorent', 'abhorrant',\n",
       "       'abhorred', 'abhorrence', 'abhorrences', 'abhorrent', 'abhors',\n",
       "       'abhout', 'abian', 'abide', 'abides', 'abideth', 'abiding', 'abig',\n",
       "       'abigail', 'abildskov', 'abilene', 'abilities', 'ability',\n",
       "       'abiliy', 'abilty', 'abingdon', 'abington', 'abiogenesis',\n",
       "       'abiogenesists', 'abject', 'abjoern', 'abjuring', 'abkect',\n",
       "       'abkhazia', 'ablagon', 'ablaze', 'ablazing', 'ablex', 'ablility',\n",
       "       'ablutions', 'ably', 'abn', 'abner', 'abnormal', 'abnormalities',\n",
       "       'abnormally', 'abo', 'aboard', 'aboce', 'abode', 'abodes', 'aboid',\n",
       "       'abolish', 'abolished', 'abolishing', 'abolishment', 'abolition',\n",
       "       'abolitionist', 'abolitionists', 'abomb', 'abominable'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.vectorizer.get_feature_names_out()[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86820ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[200], ds[200]\n",
    "#preprocessor.vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['er']\n",
    "d = {'doc_name': 'here'}\n",
    "l.extend(list(d.items()))\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e49174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds._Dataset__metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127c070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d05f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8b349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cemtom",
   "language": "python",
   "name": "cemtom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
