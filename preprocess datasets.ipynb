{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33cf072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cemtom.dataset._20newgroup import fetch_dataset\n",
    "from cemtom.preprocessing import Preprocessor\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e63f6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c42c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', 'came', 'can', 'cannot', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning', 'consequently', 'consider', 'considering', 'contain', 'containing', 'contains', 'corresponding', 'could', 'course', 'currently', 'd', 'definitely', 'described', 'despite', 'did', 'didn', 'different', 'do', 'does', 'doesn', 'doing', 'don', 'done', 'down', 'downwards', 'during', 'e', 'each', 'edu', 'eg', 'eight', 'either', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'et', 'etc', 'even', 'ever', 'every', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'exactly', 'example', 'except', 'f', 'far', 'few', 'fifth', 'first', 'five', 'followed', 'following', 'follows', 'for', 'former', 'formerly', 'forth', 'four', 'from', 'further', 'furthermore', 'g', 'get', 'gets', 'getting', 'given', 'gives', 'go', 'goes', 'going', 'gone', 'got', 'gotten', 'greetings', 'h', 'had', 'happens', 'hardly', 'has', 'have', 'having', 'he', 'hello', 'help', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', 'i', 'ie', 'if', 'ignored', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', 'isn', 'it', 'its', 'itself', 'j', 'just', 'k', 'keep', 'keeps', 'kept', 'know', 'knows', 'known', 'l', 'last', 'lately', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', 'like', 'liked', 'likely', 'little', 'look', 'looking', 'looks', 'ltd', 'm', 'mainly', 'many', 'may', 'maybe', 'me', 'mean', 'meanwhile', 'merely', 'might', 'more', 'moreover', 'most', 'mostly', 'much', 'must', 'my', 'myself', 'n', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'non', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'o', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'own', 'p', 'particular', 'particularly', 'per', 'perhaps', 'placed', 'please', 'plus', 'possible', 'presumably', 'probably', 'provides', 'q', 'que', 'quite', 'qv', 'r', 'rather', 'rd', 're', 'really', 'reasonably', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'right', 's', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'seen', 'self', 'selves', 'sensible', 'sent', 'serious', 'seriously', 'seven', 'several', 'shall', 'she', 'should', 'since', 'six', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 't', 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', 'thats', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', 'think', 'third', 'this', 'thorough', 'thoroughly', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'took', 'toward', 'towards', 'tried', 'tries', 'truly', 'try', 'trying', 'twice', 'two', 'u', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'uucp', 'v', 'value', 'various', 'very', 'via', 'viz', 'vs', 'w', 'want', 'wants', 'was', 'way', 'we', 'welcome', 'well', 'went', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'willing', 'wish', 'with', 'within', 'without', 'wonder', 'would', 'wouldn', 'x', 'y', 'yes', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves', 'z', 'zero']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "preprocessor = Preprocessor(stopwords_list=\"english\", remove_spacy_stopwords = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463b3a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to extract the dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_dataset(remove=[\"headers\", \"footers\", \"quotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce6a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>labels</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54367</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60215</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76120</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60771</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51882</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18841</th>\n",
       "      <td>58069</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18842</th>\n",
       "      <td>54046</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>\\nNot in isolated ground recepticles (usually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18843</th>\n",
       "      <td>60695</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18844</th>\n",
       "      <td>38319</td>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18845</th>\n",
       "      <td>103195</td>\n",
       "      <td>rec.autos</td>\n",
       "      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18846 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idx                    labels  \\\n",
       "0       54367          rec.sport.hockey   \n",
       "1       60215  comp.sys.ibm.pc.hardware   \n",
       "2       76120     talk.politics.mideast   \n",
       "3       60771  comp.sys.ibm.pc.hardware   \n",
       "4       51882     comp.sys.mac.hardware   \n",
       "...       ...                       ...   \n",
       "18841   58069                   sci.med   \n",
       "18842   54046           sci.electronics   \n",
       "18843   60695  comp.sys.ibm.pc.hardware   \n",
       "18844   38319             comp.graphics   \n",
       "18845  103195                 rec.autos   \n",
       "\n",
       "                                               documents  \n",
       "0      \\n\\nI am sure some bashers of Pens fans are pr...  \n",
       "1      My brother is in the market for a high-perform...  \n",
       "2      \\n\\n\\n\\n\\tFinally you said what you dream abou...  \n",
       "3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...  \n",
       "4      1)    I have an old Jasmine drive which I cann...  \n",
       "...                                                  ...  \n",
       "18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...  \n",
       "18842  \\nNot in isolated ground recepticles (usually ...  \n",
       "18843  I just installed a DX2-66 CPU in a clone mothe...  \n",
       "18844  \\nWouldn't this require a hyper-sphere.  In 3-...  \n",
       "18845  After a tip from Gary Crum (crum@fcom.cc.utah....  \n",
       "\n",
       "[18846 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"idx\": dataset.get_indices(),\n",
    "    \"labels\": dataset.get_labels(),\n",
    "    \"documents\": dataset.get_corpus()\n",
    "}\n",
    "d = pd.DataFrame(data)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca22493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d770dc804504773b90f98f40a52b6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering 18846\n",
      "I basher pen fan pretty confused lackof kind post recent pen massacre devil I bit puzzled bit relieved I put endto pittsburgher relief bit praise pen man theyare kill devil bad I jagr show whyhe regular season stat lotfo fun watch playoff bowman jagr lot offun couple game pen beat pulp jersey I disappointed islander lose finalregular season game pen rule\n",
      "vocab created 163846\n",
      "Filtering done\n"
     ]
    }
   ],
   "source": [
    "#preprocessor = Preprocessor(stopwords_list=\"english\", remove_spacy_stopwords = False)\n",
    "ds = preprocessor.preprocess(None,dataset=dataset, num_processes = 80)selfocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86820ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"idx\": ds.get_indices(), 'label': ds.get_labels(), 'document': ds.get_corpus()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a307795f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [idx, label, document]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['document']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e49174c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_documents': 18846, 'vocabulary_length': 163846}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds._Dataset__metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127c070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d05f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8b349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cemtom",
   "language": "python",
   "name": "cemtom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
